{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold\n",
    "from data_reader import MaldiDataset\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "from preprocessing_components import  ColumnDropper, SpectrumExpander, IntensityScaler, TICLogTransformer\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "from IPython.display import IFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "from IPython.display import IFrame\n",
    "import plotly.io as pio\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all seeds to make the results reproducible\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# This script is a simple starting point to classify fungal data using MALDI-TOF spectra.\n",
    "class SimpleFungusDataLoader:\n",
    "    def __init__(self, dataset_path, test_size=0.2, random_state=42):\n",
    "        # Initialize the classifier with dataset path, test size, and random state for reproducibility.\n",
    "        self.dataset_path = dataset_path\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.data = None\n",
    "        self.train_data = []\n",
    "        self.test_data = []\n",
    "\n",
    "    def load_data(self, n_step):\n",
    "        # Load the dataset using MaldiDataset\n",
    "        dataset = MaldiDataset(self.dataset_path, n_step=n_step)\n",
    "        dataset.parse_dataset()  # Parse the dataset from the specified path\n",
    "        self.data = dataset.get_data()  # Retrieve the parsed data\n",
    "\n",
    "\n",
    "    def split_data_stratify(self):\n",
    "        \"\"\"\n",
    "        Divide los datos en train y test de forma estratificada según 'genus_species_label',\n",
    "        asegurando que no haya solapamiento de 'unique_id_label' entre ambos conjuntos.\n",
    "        Las clases con menos de 2 instancias se asignan directamente al conjunto de entrenamiento.\n",
    "        \"\"\"\n",
    "        # Convertir los datos en un DataFrame\n",
    "        df = pd.DataFrame(self.data)\n",
    "\n",
    "        # Agrupar por 'unique_id_label' y seleccionar una clase representativa ('genus_species_label') para cada grupo\n",
    "        unique_id_groups = df.groupby('unique_id_label').first().reset_index()\n",
    "\n",
    "        # Identificar las clases con menos de 2 instancias\n",
    "        class_counts = unique_id_groups['genus_species_label'].value_counts()\n",
    "        small_classes = class_counts[class_counts < 2].index\n",
    "\n",
    "        # Separar los grupos con clases pequeñas y el resto\n",
    "        small_class_groups = unique_id_groups[unique_id_groups['genus_species_label'].isin(small_classes)]\n",
    "        remaining_groups = unique_id_groups[~unique_id_groups['genus_species_label'].isin(small_classes)]\n",
    "\n",
    "        # Estratificar las clases restantes\n",
    "        train_ids, test_ids = train_test_split(\n",
    "            remaining_groups['unique_id_label'],\n",
    "            test_size=self.test_size,\n",
    "            random_state=self.random_state,\n",
    "            stratify=remaining_groups['genus_species_label']  # Usar 'genus_species_label' como criterio de estratificación\n",
    "        )\n",
    "\n",
    "        # Agregar todas las instancias de clases pequeñas al conjunto de entrenamiento\n",
    "        train_ids = pd.concat([pd.Series(train_ids), small_class_groups['unique_id_label']])\n",
    "\n",
    "        # Filtrar el DataFrame original para crear los conjuntos de train y test\n",
    "        self.train_data = df[df['unique_id_label'].isin(train_ids)]  # DataFrame de entrenamiento\n",
    "        self.test_data = df[df['unique_id_label'].isin(test_ids)]  # DataFrame de prueba\n",
    "\n",
    "        # Verificar que no haya solapamiento de 'unique_id_label' entre train y test\n",
    "        train_unique_ids = set(self.train_data['unique_id_label'])\n",
    "        test_unique_ids = set(self.test_data['unique_id_label'])\n",
    "        assert len(train_unique_ids.intersection(test_unique_ids)) == 0, \"Unique ID labels overlap between train and test\"\n",
    "\n",
    "        # Imprimir estadísticas\n",
    "        print(f\"Number of unique_id_labels in train data: {len(train_unique_ids)}\")\n",
    "        print(f\"Number of unique_id_labels in test data: {len(test_unique_ids)}\")\n",
    "        print(f\"Number of samples in train data: {len(self.train_data)}\")\n",
    "        print(f\"Number of samples in test data: {len(self.test_data)}\")\n",
    "        print(f\"Number of classes to predict: {len(self.train_data['genus_species_label'].unique())}\")\n",
    "\n",
    "\n",
    "\n",
    "    def plot_data_distribution(self):\n",
    "        \"\"\"\n",
    "        Grafica la distribución de las clases ('genus_species_label') en los conjuntos de\n",
    "        entrenamiento y prueba para visualizar las proporciones después de la división estratificada.\n",
    "        \"\"\"\n",
    "        # Contar las etiquetas en los conjuntos de entrenamiento y prueba\n",
    "        train_counts = self.train_data['genus_species_label'].value_counts()\n",
    "        test_counts = self.test_data['genus_species_label'].value_counts()\n",
    "\n",
    "        # Unificar las etiquetas para asegurar que ambas series tengan los mismos índices\n",
    "        all_labels = pd.Index(train_counts.index).union(test_counts.index)\n",
    "        train_counts = train_counts.reindex(all_labels, fill_value=0)\n",
    "        test_counts = test_counts.reindex(all_labels, fill_value=0)\n",
    "\n",
    "        # Crear gráfico\n",
    "        x = np.arange(len(all_labels))  # Posiciones de las barras\n",
    "        width = 0.4  # Ancho de las barras\n",
    "\n",
    "        plt.figure(figsize=(14, 8))  # Tamaño del gráfico\n",
    "        plt.bar(x - width / 2, train_counts, width, label='Train', alpha=0.8, color='blue')\n",
    "        plt.bar(x + width / 2, test_counts, width, label='Test', alpha=0.8, color='orange')\n",
    "\n",
    "        # Configurar etiquetas y título\n",
    "        plt.xlabel('Genus+Species Label', fontsize=12)\n",
    "        plt.ylabel('Number of Samples', fontsize=12)\n",
    "        plt.title('Distribution of Genus+Species Labels in Train and Test Data', fontsize=14)\n",
    "        plt.xticks(x, all_labels, rotation=90, fontsize=10)  # Etiquetas en el eje X\n",
    "        plt.legend(fontsize=12)\n",
    "\n",
    "        # Ajustar diseño\n",
    "        plt.tight_layout()\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    \n",
    "    def get_train_data(self):\n",
    "        return self.train_data\n",
    "    \n",
    "    def get_test_data(self):\n",
    "        return self.test_data\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleta\\Documents\\TFM\\FungusClassifier\\data_reader.py:299: RuntimeWarning: invalid value encountered in divide\n",
      "  intensity=SpectrumObj.intensity / SpectrumObj.intensity.sum() * self.sum,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Skipping nan spectrum\n",
      "Number of unique_id_labels in train data: 268\n",
      "Number of unique_id_labels in test data: 64\n",
      "Number of samples in train data: 6452\n",
      "Number of samples in test data: 1476\n",
      "Number of classes to predict: 60\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset path (update this path to where your dataset is located)\n",
    "dataset_path = \"data/fungus_db\"\n",
    "\n",
    "# Initialize the classifier with the dataset path\n",
    "fungus_identifier = SimpleFungusDataLoader(dataset_path)\n",
    "\n",
    "fungus_identifier.load_data(n_step=3)\n",
    "\n",
    "# Load and split the data into training and test sets.\n",
    "fungus_identifier.split_data_stratify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargando pipeline de preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = joblib.load('preproc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_genus = LabelEncoder()\n",
    "label_encoder_species = LabelEncoder()\n",
    "x_train = fungus_identifier.get_train_data()\n",
    "X = x_train.drop(columns=['genus_species_label', 'genus_label'])\n",
    "y_species = label_encoder_species.fit_transform(x_train['genus_species_label'])\n",
    "y_genus = label_encoder_genus.fit_transform(x_train['genus_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSIC Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos clásicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_cross_validation(pipe, X_df, y, group_col='unique_id_label',\n",
    "                                         n_splits=6, random_state=42):\n",
    "    \"\"\"\n",
    "    Evalúa un pipeline con GroupKFold, calculando métricas globales y por clase,\n",
    "    asegurando que todas las muestras con el mismo group_col queden en el mismo fold.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    pipe        : Pipeline de sklearn (preproc + clf)\n",
    "    X_df        : pandas.DataFrame con las features crudas _incluyendo_ group_col\n",
    "    y           : array‑like 1D de etiquetas codificadas\n",
    "    group_col   : str, nombre de la columna en X_df que contiene los grupos\n",
    "    n_splits    : int, número de folds\n",
    "    random_state: semilla para reproducibilidad (solo afecta al ordering interno)\n",
    "    \n",
    "    Devuelve\n",
    "    -------\n",
    "    df_global   : DataFrame con métricas globales por fold\n",
    "    df_class    : DataFrame con métricas por clase por fold\n",
    "    \"\"\"\n",
    "    groups = X_df[group_col].values\n",
    "    cv = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    global_metrics = []\n",
    "    per_class      = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(X_df, y, groups), start=1):\n",
    "        # 1) Chequeo de índices\n",
    "        assert set(train_idx).isdisjoint(test_idx), \\\n",
    "            f\"Fold {fold}: ¡solapamiento de índices!\"\n",
    "        \n",
    "        # 2) Extraer splits\n",
    "        X_train, X_test = X_df.iloc[train_idx], X_df.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # 3) Ajustar pipeline y predecir\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # 4) Métricas globales\n",
    "        global_metrics.append({\n",
    "            \"fold\":             fold,\n",
    "            \"accuracy\":         accuracy_score(y_test, y_pred),\n",
    "            \"precision_macro\":  precision_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "            \"recall_macro\":     recall_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "            \"f1_macro\":         f1_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "            \"balanced_accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "        })\n",
    "        \n",
    "        # 5) Métricas por clase\n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        for cls, m in report.items():\n",
    "            if cls in (\"accuracy\", \"macro avg\", \"weighted avg\"):\n",
    "                continue\n",
    "            per_class.append({\n",
    "                \"fold\":     fold,\n",
    "                \"class\":    cls,\n",
    "                \"precision\": m[\"precision\"],\n",
    "                \"recall\":    m[\"recall\"],\n",
    "                \"f1\":        m[\"f1-score\"],\n",
    "                \"support\":   m[\"support\"]\n",
    "            })\n",
    "        \n",
    "        # 6) Mostrar informe de texto de este fold\n",
    "        print(f\"\\n--- Fold {fold} (Groups) ---\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    \n",
    "    # 7) DataFrames de salida\n",
    "    df_global = pd.DataFrame(global_metrics).set_index(\"fold\")\n",
    "    df_class  = pd.DataFrame(per_class)\n",
    "    \n",
    "    # 8) Resúmenes finales\n",
    "    print(\"\\nMétricas globales por fold:\")\n",
    "    print(df_global)\n",
    "    print(\"\\nResumen global (media ± std):\")\n",
    "    print(df_global.agg([\"mean\",\"std\"]))\n",
    "    print(\"\\nMétricas por clase (media ± std sobre folds):\")\n",
    "    print(\n",
    "        df_class\n",
    "          .groupby(\"class\")[[\"precision\",\"recall\",\"f1\"]]\n",
    "          .agg([\"mean\",\"std\"])\n",
    "    )\n",
    "    \n",
    "    return df_global, df_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleta\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 (Groups) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.38      0.55        71\n",
      "           3       0.94      1.00      0.97        89\n",
      "           4       0.00      0.00      0.00         0\n",
      "           6       1.00      1.00      1.00        47\n",
      "           7       1.00      1.00      1.00       101\n",
      "           9       0.46      0.51      0.49        51\n",
      "          10       0.35      1.00      0.52        24\n",
      "          12       0.90      0.76      0.83        93\n",
      "          14       0.00      0.00      0.00        20\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00        20\n",
      "          22       1.00      1.00      1.00        48\n",
      "          23       0.90      1.00      0.95        99\n",
      "          25       0.59      0.55      0.57        66\n",
      "          26       1.00      1.00      1.00        44\n",
      "          31       0.00      0.00      0.00        20\n",
      "          32       0.64      1.00      0.78        27\n",
      "          33       0.54      0.56      0.55        48\n",
      "          34       1.00      0.22      0.37        49\n",
      "          35       0.54      0.53      0.53        91\n",
      "          36       0.00      0.00      0.00         0\n",
      "          39       1.00      1.00      1.00        21\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       1.00      0.12      0.22        24\n",
      "          42       1.00      0.76      0.86        49\n",
      "          43       0.00      0.00      0.00        23\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       1.00      1.00      1.00        28\n",
      "          47       0.83      0.95      0.88        56\n",
      "          49       1.00      0.96      0.98        48\n",
      "          50       1.00      1.00      1.00        49\n",
      "          52       1.00      1.00      1.00        47\n",
      "          53       1.00      1.00      1.00        49\n",
      "          55       0.00      0.00      0.00        21\n",
      "          56       0.86      1.00      0.92        24\n",
      "          58       0.76      1.00      0.86        66\n",
      "          59       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.76      1537\n",
      "   macro avg       0.60      0.57      0.56      1537\n",
      "weighted avg       0.80      0.76      0.76      1537\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleta\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 2 (Groups) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.36      0.56      0.44        43\n",
      "           3       0.93      1.00      0.96        64\n",
      "           4       0.00      0.00      0.00        27\n",
      "           5       0.77      1.00      0.87        23\n",
      "           6       0.96      1.00      0.98        25\n",
      "           7       0.79      1.00      0.88       140\n",
      "           8       0.00      0.00      0.00        27\n",
      "           9       0.98      0.73      0.84        64\n",
      "          10       0.54      0.34      0.42        64\n",
      "          11       0.00      0.00      0.00        24\n",
      "          12       0.51      1.00      0.68        53\n",
      "          13       0.00      0.00      0.00        25\n",
      "          17       1.00      1.00      1.00        24\n",
      "          18       1.00      1.00      1.00        45\n",
      "          19       1.00      1.00      1.00        30\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00        51\n",
      "          22       1.00      1.00      1.00        42\n",
      "          23       0.93      1.00      0.97        70\n",
      "          25       0.56      1.00      0.72        22\n",
      "          26       1.00      1.00      1.00        28\n",
      "          32       1.00      0.54      0.70        95\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       1.00      1.00      1.00        20\n",
      "          36       0.00      0.00      0.00        24\n",
      "          38       1.00      1.00      1.00        24\n",
      "          39       1.00      1.00      1.00        24\n",
      "          41       1.00      1.00      1.00        46\n",
      "          42       1.00      0.92      0.96        26\n",
      "          43       0.96      1.00      0.98        23\n",
      "          45       1.00      0.77      0.87        22\n",
      "          46       0.35      1.00      0.52        27\n",
      "          47       1.00      1.00      1.00        22\n",
      "          49       1.00      1.00      1.00        24\n",
      "          50       1.00      1.00      1.00        51\n",
      "          51       1.00      1.00      1.00        50\n",
      "          52       1.00      1.00      1.00        64\n",
      "          53       1.00      1.00      1.00        25\n",
      "          56       1.00      1.00      1.00        71\n",
      "          57       1.00      1.00      1.00        23\n",
      "          58       1.00      1.00      1.00        47\n",
      "\n",
      "    accuracy                           0.81      1642\n",
      "   macro avg       0.73      0.76      0.73      1642\n",
      "weighted avg       0.80      0.81      0.79      1642\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleta\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 3 (Groups) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        41\n",
      "           1       0.52      1.00      0.69        24\n",
      "           2       0.00      0.00      0.00        22\n",
      "           3       0.27      1.00      0.42        26\n",
      "           4       0.00      0.00      0.00         0\n",
      "           6       0.98      1.00      0.99        98\n",
      "           7       0.71      0.96      0.82        49\n",
      "           9       0.51      1.00      0.67        45\n",
      "          10       1.00      0.75      0.86        87\n",
      "          12       0.54      1.00      0.70        27\n",
      "          15       0.00      0.00      0.00        40\n",
      "          19       1.00      1.00      1.00        26\n",
      "          20       0.00      0.00      0.00        23\n",
      "          22       1.00      1.00      1.00        20\n",
      "          23       0.75      1.00      0.86        83\n",
      "          24       1.00      1.00      1.00        54\n",
      "          25       1.00      0.49      0.66        43\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00        22\n",
      "          29       0.00      0.00      0.00        27\n",
      "          30       0.00      0.00      0.00        27\n",
      "          32       0.34      1.00      0.51        24\n",
      "          33       1.00      0.57      0.73        54\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.96      0.57      0.72        47\n",
      "          36       0.00      0.00      0.00        27\n",
      "          38       1.00      0.62      0.76       117\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00        27\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       1.00      0.97      0.99        72\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00        57\n",
      "          45       0.51      1.00      0.68        24\n",
      "          46       0.92      1.00      0.96        22\n",
      "          47       0.43      1.00      0.60        20\n",
      "          48       0.00      0.00      0.00        78\n",
      "          49       1.00      1.00      1.00        24\n",
      "          50       1.00      1.00      1.00        23\n",
      "          51       1.00      1.00      1.00       117\n",
      "          52       1.00      1.00      1.00        21\n",
      "          54       1.00      1.00      1.00        24\n",
      "          56       0.99      1.00      0.99        67\n",
      "          58       1.00      1.00      1.00        24\n",
      "          59       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.71      1653\n",
      "   macro avg       0.52      0.58      0.52      1653\n",
      "weighted avg       0.70      0.71      0.68      1653\n",
      "\n",
      "\n",
      "--- Fold 4 (Groups) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       0.96      0.74      0.83        68\n",
      "           3       0.95      1.00      0.97        94\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       1.00      1.00      1.00        30\n",
      "           6       1.00      1.00      1.00        52\n",
      "           7       0.69      1.00      0.81        74\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.80      1.00      0.89        28\n",
      "          10       0.57      1.00      0.73        24\n",
      "          12       0.80      1.00      0.89        74\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.47      0.85      0.61        27\n",
      "          16       0.00      0.00      0.00        22\n",
      "          18       1.00      1.00      1.00        20\n",
      "          22       1.00      1.00      1.00        23\n",
      "          23       0.98      1.00      0.99       122\n",
      "          24       1.00      1.00      1.00        47\n",
      "          25       0.91      0.97      0.94        70\n",
      "          27       0.00      0.00      0.00        26\n",
      "          31       0.00      0.00      0.00        25\n",
      "          32       0.27      0.74      0.40        27\n",
      "          33       0.89      1.00      0.94        25\n",
      "          34       1.00      0.04      0.08        75\n",
      "          35       0.00      0.00      0.00        20\n",
      "          36       0.00      0.00      0.00        27\n",
      "          37       0.00      0.00      0.00        30\n",
      "          38       1.00      1.00      1.00        24\n",
      "          39       1.00      1.00      1.00        69\n",
      "          41       1.00      1.00      1.00        47\n",
      "          43       1.00      0.96      0.98        26\n",
      "          46       1.00      1.00      1.00        67\n",
      "          47       0.00      0.00      0.00         0\n",
      "          49       1.00      0.63      0.77        76\n",
      "          50       1.00      0.97      0.99        73\n",
      "          52       1.00      1.00      1.00        20\n",
      "          54       1.00      1.00      1.00        24\n",
      "          56       0.91      1.00      0.95        70\n",
      "          57       1.00      1.00      1.00        24\n",
      "          58       1.00      1.00      1.00        23\n",
      "          59       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.82      1620\n",
      "   macro avg       0.69      0.71      0.68      1620\n",
      "weighted avg       0.84      0.82      0.80      1620\n",
      "\n",
      "\n",
      "Métricas globales por fold:\n",
      "      accuracy  precision_macro  recall_macro  f1_macro  balanced_accuracy\n",
      "fold                                                                      \n",
      "1     0.762524         0.597668      0.571751  0.559749           0.696822\n",
      "2     0.813033         0.729692      0.758784  0.733033           0.796723\n",
      "3     0.705989         0.520547      0.576241  0.524155           0.682390\n",
      "4     0.824691         0.687996      0.705001  0.677483           0.781217\n",
      "\n",
      "Resumen global (media ± std):\n",
      "      accuracy  precision_macro  recall_macro  f1_macro  balanced_accuracy\n",
      "mean  0.776559         0.633976      0.652944  0.623605           0.739288\n",
      "std   0.054235         0.093567      0.093786  0.098057           0.058016\n",
      "\n",
      "Métricas por clase (media ± std sobre folds):\n",
      "      precision              recall                  f1          \n",
      "           mean       std      mean       std      mean       std\n",
      "class                                                            \n",
      "0      1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "1      0.711728  0.317684  0.668429  0.264325  0.627609  0.169926\n",
      "10     0.615239  0.273829  0.772719  0.309829  0.630831  0.196997\n",
      "11     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "12     0.689411  0.191418  0.940860  0.118280  0.774483  0.101159\n",
      "13     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "14     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "15     0.156463  0.271001  0.283951  0.491817  0.201754  0.349449\n",
      "16     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "17     0.500000  0.707107  0.500000  0.707107  0.500000  0.707107\n",
      "18     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "19     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "2      0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "20     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "21     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "22     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "23     0.892937  0.098494  1.000000  0.000000  0.941215  0.057077\n",
      "24     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "25     0.765233  0.220773  0.751314  0.271914  0.720605  0.158102\n",
      "26     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "27     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "28     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "29     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "3      0.769795  0.336446  1.000000  0.000000  0.830811  0.274346\n",
      "30     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "31     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "32     0.564922  0.331326  0.819396  0.224543  0.597969  0.174206\n",
      "33     0.810952  0.240689  0.712191  0.249317  0.741276  0.196457\n",
      "34     0.500000  0.577350  0.066122  0.107249  0.110897  0.174326\n",
      "35     0.625903  0.466798  0.525485  0.409757  0.563333  0.421690\n",
      "36     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "37     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "38     1.000000  0.000000  0.871795  0.222058  0.920635  0.137464\n",
      "39     0.750000  0.500000  0.750000  0.500000  0.750000  0.500000\n",
      "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "40     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "41     0.750000  0.500000  0.531250  0.543666  0.555556  0.521157\n",
      "42     1.000000  0.000000  0.883467  0.113851  0.935460  0.066228\n",
      "43     0.489583  0.565578  0.490385  0.566465  0.489779  0.565548\n",
      "44     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "45     0.503546  0.500038  0.590909  0.524207  0.515950  0.457419\n",
      "46     0.816829  0.313259  1.000000  0.000000  0.868938  0.234037\n",
      "47     0.563414  0.446141  0.736607  0.491720  0.620087  0.446719\n",
      "48     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "49     1.000000  0.000000  0.897478  0.178351  0.938229  0.109816\n",
      "5      0.883333  0.164992  1.000000  0.000000  0.933962  0.093391\n",
      "50     1.000000  0.000000  0.993151  0.013699  0.996528  0.006944\n",
      "51     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "52     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "53     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "54     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "55     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "56     0.937882  0.066968  1.000000  0.000000  0.967013  0.035995\n",
      "57     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "58     0.939655  0.120690  1.000000  0.000000  0.965686  0.068627\n",
      "59     0.666667  0.577350  0.666667  0.577350  0.666667  0.577350\n",
      "6      0.985385  0.018483  1.000000  0.000000  0.992573  0.009414\n",
      "7      0.797067  0.142539  0.989796  0.020408  0.878465  0.087150\n",
      "8      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "9      0.687268  0.245378  0.811045  0.236666  0.721449  0.182435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleta\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(      accuracy  precision_macro  recall_macro  f1_macro  balanced_accuracy\n",
       " fold                                                                      \n",
       " 1     0.762524         0.597668      0.571751  0.559749           0.696822\n",
       " 2     0.813033         0.729692      0.758784  0.733033           0.796723\n",
       " 3     0.705989         0.520547      0.576241  0.524155           0.682390\n",
       " 4     0.824691         0.687996      0.705001  0.677483           0.781217,\n",
       "      fold class  precision    recall        f1  support\n",
       " 0       1     1   1.000000  0.380282  0.551020     71.0\n",
       " 1       1     3   0.936842  1.000000  0.967391     89.0\n",
       " 2       1     4   0.000000  0.000000  0.000000      0.0\n",
       " 3       1     6   1.000000  1.000000  1.000000     47.0\n",
       " 4       1     7   1.000000  1.000000  1.000000    101.0\n",
       " ..    ...   ...        ...       ...       ...      ...\n",
       " 162     4    54   1.000000  1.000000  1.000000     24.0\n",
       " 163     4    56   0.909091  1.000000  0.952381     70.0\n",
       " 164     4    57   1.000000  1.000000  1.000000     24.0\n",
       " 165     4    58   1.000000  1.000000  1.000000     23.0\n",
       " 166     4    59   1.000000  1.000000  1.000000     24.0\n",
       " \n",
       " [167 rows x 6 columns])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_pipeline = Pipeline([\n",
    "    ('preproc', preproc),\n",
    "    ('clf', knn_classifier)\n",
    "]\n",
    ")\n",
    "x_df = X.copy()\n",
    "evaluate_with_cross_validation(knn_pipeline, x_df, y_species, n_splits=4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./bin_3_models_pipelines/3_bin_knn_pipeline.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"bin_3_models_pipelines\"):\n",
    "    os.makedirs(\"bin_3_models_pipelines\")\n",
    "\n",
    "joblib.dump(knn_pipeline, \"./bin_3_models_pipelines/3_bin_knn_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_proc = preproc.fit_transform(X.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "groups = X['unique_id_label'].values\n",
    "cv = GroupKFold(n_splits=6)\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size' : [30, 40, 50]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(knn_classifier, param_grid, cv=cv.split(x_proc, y_species, groups), scoring='balanced_accuracy', n_jobs=1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(x_proc, y_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'leaf_size': 30, 'n_neighbors': 3, 'weights': 'uniform'}:   0.7564179126005662\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'n_neighbors': 3, 'weights': 'distance'}:   0.7573479744520366\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'uniform'}:   0.7512066215186435\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'distance'}:   0.7532055620058609\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'uniform'}:   0.7476851057948172\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'distance'}:   0.7501952985249378\n",
      "{'algorithm': 'auto', 'leaf_size': 40, 'n_neighbors': 3, 'weights': 'uniform'}:   0.7564179126005662\n",
      "{'algorithm': 'auto', 'leaf_size': 40, 'n_neighbors': 3, 'weights': 'distance'}:   0.7573479744520366\n",
      "{'algorithm': 'auto', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'uniform'}:   0.7512066215186435\n",
      "{'algorithm': 'auto', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'distance'}:   0.7532055620058609\n",
      "{'algorithm': 'auto', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'uniform'}:   0.7476851057948172\n",
      "{'algorithm': 'auto', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'distance'}:   0.7501952985249378\n",
      "{'algorithm': 'auto', 'leaf_size': 50, 'n_neighbors': 3, 'weights': 'uniform'}:   0.7564179126005662\n",
      "{'algorithm': 'auto', 'leaf_size': 50, 'n_neighbors': 3, 'weights': 'distance'}:   0.7573479744520366\n",
      "{'algorithm': 'auto', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'uniform'}:   0.7512066215186435\n",
      "{'algorithm': 'auto', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'distance'}:   0.7532055620058609\n",
      "{'algorithm': 'auto', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'uniform'}:   0.7476851057948172\n",
      "{'algorithm': 'auto', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'distance'}:   0.7501952985249378\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 3, 'weights': 'uniform'}:   0.7564179126005662\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 3, 'weights': 'distance'}:   0.7573479744520366\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'uniform'}:   0.7512066215186435\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'distance'}:   0.7532055620058609\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'uniform'}:   0.7476851057948172\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'distance'}:   0.7501952985249378\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 3, 'weights': 'uniform'}:   0.7564179126005662\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 3, 'weights': 'distance'}:   0.7573479744520366\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'uniform'}:   0.7512066215186435\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'distance'}:   0.7532055620058609\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'uniform'}:   0.7476851057948172\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'distance'}:   0.7501952985249378\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 3, 'weights': 'uniform'}:   0.7564179126005662\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 3, 'weights': 'distance'}:   0.7573479744520366\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'uniform'}:   0.7512066215186435\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'distance'}:   0.7532055620058609\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'uniform'}:   0.7476851057948172\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'distance'}:   0.7501952985249378\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 3, 'weights': 'uniform'}:   0.7564179126005662\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 3, 'weights': 'distance'}:   0.7573479744520366\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'uniform'}:   0.7512066215186435\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'distance'}:   0.7532055620058609\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'uniform'}:   0.7476851057948172\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'distance'}:   0.7501952985249378\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 3, 'weights': 'uniform'}:   0.7564179126005662\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 3, 'weights': 'distance'}:   0.7573479744520366\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'uniform'}:   0.7512066215186435\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'distance'}:   0.7532055620058609\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'uniform'}:   0.7476851057948172\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'distance'}:   0.7501952985249378\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 3, 'weights': 'uniform'}:   0.7564179126005662\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 3, 'weights': 'distance'}:   0.7573479744520366\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'uniform'}:   0.7512066215186435\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'distance'}:   0.7532055620058609\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'uniform'}:   0.7476851057948172\n",
      "{'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'distance'}:   0.7501952985249378\n",
      "{'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 3, 'weights': 'uniform'}:   0.7564179126005662\n",
      "{'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 3, 'weights': 'distance'}:   0.7573479744520366\n",
      "{'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'uniform'}:   0.7512066215186435\n",
      "{'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'distance'}:   0.7532055620058609\n",
      "{'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'uniform'}:   0.7476851057948172\n",
      "{'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'distance'}:   0.7501952985249378\n",
      "{'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 3, 'weights': 'uniform'}:   0.7564179126005662\n",
      "{'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 3, 'weights': 'distance'}:   0.7573479744520366\n",
      "{'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'uniform'}:   0.7512066215186435\n",
      "{'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'distance'}:   0.7532055620058609\n",
      "{'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'uniform'}:   0.7476851057948172\n",
      "{'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'distance'}:   0.7501952985249378\n",
      "{'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 3, 'weights': 'uniform'}:   0.7564179126005662\n",
      "{'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 3, 'weights': 'distance'}:   0.7573479744520366\n",
      "{'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'uniform'}:   0.7512066215186435\n",
      "{'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'distance'}:   0.7532055620058609\n",
      "{'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'uniform'}:   0.7476851057948172\n",
      "{'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'distance'}:   0.7501952985249378\n"
     ]
    }
   ],
   "source": [
    "results = grid_search.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f'{params}:   {mean_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preproc', preproc),\n",
    "    ('clf', rf_classifier)\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleta\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2524: UserWarning:\n",
      "\n",
      "y_pred contains classes not in y_true\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 (Groups) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       0.31      0.57      0.40        51\n",
      "           3       0.55      1.00      0.71        69\n",
      "           4       0.00      0.00      0.00        27\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.99      1.00      0.99        76\n",
      "           7       1.00      1.00      1.00       195\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.73      0.65      0.69        69\n",
      "          10       0.67      0.41      0.51       109\n",
      "          12       0.72      0.98      0.83       106\n",
      "          14       0.00      0.00      0.00        20\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00        22\n",
      "          19       0.00      0.00      0.00        56\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       1.00      1.00      1.00        23\n",
      "          23       0.79      1.00      0.89        93\n",
      "          24       1.00      0.82      0.90        74\n",
      "          25       0.71      0.91      0.80        66\n",
      "          26       1.00      1.00      1.00        22\n",
      "          27       0.00      0.00      0.00        26\n",
      "          29       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00        25\n",
      "          32       0.69      1.00      0.81        24\n",
      "          33       0.67      0.75      0.71        75\n",
      "          34       0.39      1.00      0.56        27\n",
      "          35       0.73      0.75      0.74        91\n",
      "          36       0.00      0.00      0.00        27\n",
      "          38       0.82      1.00      0.90        73\n",
      "          39       1.00      1.00      1.00        69\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.80      0.09      0.16        45\n",
      "          42       1.00      1.00      1.00        53\n",
      "          45       0.00      0.00      0.00        22\n",
      "          46       0.74      1.00      0.85        77\n",
      "          47       1.00      1.00      1.00        20\n",
      "          48       0.00      0.00      0.00        27\n",
      "          49       1.00      1.00      1.00        24\n",
      "          51       1.00      1.00      1.00        20\n",
      "          52       1.00      1.00      1.00        24\n",
      "          54       0.00      0.00      0.00        48\n",
      "          55       0.00      0.00      0.00        21\n",
      "          56       0.86      1.00      0.92       114\n",
      "          57       0.00      0.00      0.00        47\n",
      "          58       0.27      1.00      0.42        47\n",
      "          59       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.73      2148\n",
      "   macro avg       0.49      0.54      0.50      2148\n",
      "weighted avg       0.66      0.73      0.68      2148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleta\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2524: UserWarning:\n",
      "\n",
      "y_pred contains classes not in y_true\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 2 (Groups) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        44\n",
      "           1       0.98      0.48      0.65        89\n",
      "           2       0.00      0.00      0.00        22\n",
      "           3       0.98      0.99      0.99       158\n",
      "           4       0.00      0.00      0.00         0\n",
      "           6       1.00      1.00      1.00        76\n",
      "           7       0.77      1.00      0.87       169\n",
      "           8       0.00      0.00      0.00        27\n",
      "           9       0.66      1.00      0.79        73\n",
      "          10       0.30      1.00      0.46        20\n",
      "          11       0.00      0.00      0.00        24\n",
      "          12       0.60      0.53      0.57        73\n",
      "          15       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       1.00      0.13      0.24        45\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00        23\n",
      "          21       1.00      0.19      0.32        26\n",
      "          22       0.83      1.00      0.91        44\n",
      "          23       0.83      1.00      0.90       147\n",
      "          24       0.96      1.00      0.98        27\n",
      "          25       1.00      0.68      0.81        69\n",
      "          26       1.00      1.00      1.00        28\n",
      "          28       0.00      0.00      0.00        22\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.83      1.00      0.90        95\n",
      "          33       0.98      1.00      0.99        52\n",
      "          34       0.86      0.88      0.87        49\n",
      "          35       0.00      0.00      0.00        40\n",
      "          36       0.81      0.96      0.88        27\n",
      "          38       1.00      0.40      0.57        45\n",
      "          39       1.00      1.00      1.00        24\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       1.00      0.35      0.52        48\n",
      "          42       1.00      1.00      1.00        23\n",
      "          43       1.00      0.50      0.67        26\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.25      0.46      0.32        24\n",
      "          46       1.00      1.00      1.00        47\n",
      "          47       1.00      1.00      1.00        56\n",
      "          49       0.87      1.00      0.93        46\n",
      "          50       1.00      1.00      1.00       123\n",
      "          51       1.00      0.99      0.99        69\n",
      "          52       1.00      1.00      1.00        44\n",
      "          53       1.00      1.00      1.00        22\n",
      "          56       0.89      1.00      0.94        24\n",
      "          58       1.00      1.00      1.00        67\n",
      "\n",
      "    accuracy                           0.81      2157\n",
      "   macro avg       0.65      0.61      0.60      2157\n",
      "weighted avg       0.83      0.81      0.79      2157\n",
      "\n",
      "\n",
      "--- Fold 3 (Groups) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        43\n",
      "           1       0.82      0.98      0.90        66\n",
      "           3       1.00      1.00      1.00        46\n",
      "           5       0.00      0.00      0.00        53\n",
      "           6       0.65      1.00      0.79        70\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.66      1.00      0.79        46\n",
      "          10       0.99      0.94      0.96        70\n",
      "          12       0.79      1.00      0.88        68\n",
      "          13       0.00      0.00      0.00        25\n",
      "          15       0.00      0.00      0.00        67\n",
      "          17       0.00      0.00      0.00        44\n",
      "          18       1.00      1.00      1.00        20\n",
      "          21       0.00      0.00      0.00        25\n",
      "          22       1.00      1.00      1.00        66\n",
      "          23       0.78      1.00      0.88       134\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       1.00      0.68      0.81        66\n",
      "          26       1.00      1.00      1.00        22\n",
      "          27       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00        27\n",
      "          30       0.00      0.00      0.00        27\n",
      "          31       0.00      0.00      0.00        20\n",
      "          32       0.66      1.00      0.79        54\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00        48\n",
      "          35       0.36      0.68      0.47        47\n",
      "          36       0.00      0.00      0.00        24\n",
      "          37       0.00      0.00      0.00        30\n",
      "          38       0.96      1.00      0.98        47\n",
      "          39       0.42      1.00      0.59        21\n",
      "          40       0.00      0.00      0.00        27\n",
      "          41       0.41      1.00      0.58        24\n",
      "          42       0.77      1.00      0.87        71\n",
      "          43       0.46      0.96      0.62        46\n",
      "          44       0.00      0.00      0.00        57\n",
      "          46       0.61      1.00      0.75        20\n",
      "          47       0.88      1.00      0.94        22\n",
      "          48       0.00      0.00      0.00        51\n",
      "          49       0.74      1.00      0.85       102\n",
      "          50       1.00      0.68      0.81        73\n",
      "          51       1.00      1.00      1.00        78\n",
      "          52       1.00      1.00      1.00        84\n",
      "          53       1.00      1.00      1.00        52\n",
      "          56       0.78      1.00      0.88        94\n",
      "          58       1.00      1.00      1.00        46\n",
      "          59       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.71      2147\n",
      "   macro avg       0.47      0.56      0.50      2147\n",
      "weighted avg       0.62      0.71      0.65      2147\n",
      "\n",
      "\n",
      "Métricas globales por fold:\n",
      "      accuracy  precision_macro  recall_macro  f1_macro  balanced_accuracy\n",
      "fold                                                                      \n",
      "1     0.729050         0.488267      0.540229  0.495812           0.632463\n",
      "2     0.808530         0.646664      0.607583  0.597418           0.713910\n",
      "3     0.713554         0.473088      0.561080  0.502891           0.626322\n",
      "\n",
      "Resumen global (media ± std):\n",
      "      accuracy  precision_macro  recall_macro  f1_macro  balanced_accuracy\n",
      "mean  0.750378         0.536006      0.569631  0.532041           0.657565\n",
      "std   0.050954         0.096133      0.034481  0.056729           0.048893\n",
      "\n",
      "Métricas por clase (media ± std sobre folds):\n",
      "      precision              recall                  f1          \n",
      "           mean       std      mean       std      mean       std\n",
      "class                                                            \n",
      "0      0.992424  0.013122  1.000000  0.000000  0.996169  0.006636\n",
      "1      0.703962  0.348272  0.678874  0.268407  0.648649  0.246893\n",
      "10     0.651741  0.343716  0.785234  0.323762  0.644879  0.277140\n",
      "11     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "12     0.702646  0.096183  0.838460  0.263625  0.759007  0.170019\n",
      "13     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "14     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "15     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "16     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "17     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "18     1.000000  0.000000  0.566667  0.612826  0.617647  0.540729\n",
      "19     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "2      0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "20     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "21     0.333333  0.577350  0.064103  0.111029  0.107527  0.186242\n",
      "22     0.943396  0.098041  1.000000  0.000000  0.969072  0.053569\n",
      "23     0.801447  0.021863  1.000000  0.000000  0.889673  0.013409\n",
      "24     0.654762  0.567322  0.608108  0.533912  0.628507  0.545703\n",
      "25     0.904762  0.164957  0.757356  0.131407  0.807052  0.006112\n",
      "26     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "27     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "28     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "29     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "3      0.844417  0.253414  0.997890  0.003654  0.899587  0.163148\n",
      "30     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "31     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "32     0.723446  0.089922  1.000000  0.000000  0.837480  0.059073\n",
      "33     0.551944  0.501953  0.582222  0.519886  0.566446  0.510365\n",
      "34     0.415238  0.430759  0.625850  0.545449  0.475129  0.440051\n",
      "35     0.362246  0.365637  0.476035  0.413593  0.402095  0.373835\n",
      "36     0.270833  0.469097  0.320988  0.555967  0.293785  0.508851\n",
      "37     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "38     0.926469  0.094247  0.800000  0.346410  0.817277  0.216447\n",
      "39     0.806667  0.334863  1.000000  0.000000  0.863850  0.235819\n",
      "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "40     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "41     0.735593  0.301809  0.481019  0.468614  0.420463  0.227252\n",
      "42     0.923913  0.131786  1.000000  0.000000  0.957055  0.074383\n",
      "43     0.731579  0.379605  0.728261  0.322810  0.645390  0.030090\n",
      "44     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "45     0.125000  0.176777  0.229167  0.324091  0.161765  0.228770\n",
      "46     0.782148  0.200263  1.000000  0.000000  0.868515  0.123594\n",
      "47     0.960000  0.069282  1.000000  0.000000  0.978723  0.036852\n",
      "48     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "49     0.869018  0.130438  1.000000  0.000000  0.926431  0.075041\n",
      "5      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "50     1.000000  0.000000  0.842466  0.222787  0.906504  0.132223\n",
      "51     1.000000  0.000000  0.995169  0.008367  0.997567  0.004214\n",
      "52     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "53     1.000000  0.000000  1.000000  0.000000  1.000000  0.000000\n",
      "54     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "55     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "56     0.843122  0.054157  1.000000  0.000000  0.914253  0.032254\n",
      "57     0.000000       NaN  0.000000       NaN  0.000000       NaN\n",
      "58     0.755682  0.423172  1.000000  0.000000  0.807175  0.333983\n",
      "59     0.500000  0.707107  0.500000  0.707107  0.500000  0.707107\n",
      "6      0.878387  0.199498  1.000000  0.000000  0.926660  0.121412\n",
      "7      0.590563  0.524028  0.666667  0.577350  0.623711  0.543979\n",
      "8      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "9      0.680202  0.039495  0.884058  0.200817  0.757868  0.061354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleta\\anaconda3\\envs\\TFM\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2524: UserWarning:\n",
      "\n",
      "y_pred contains classes not in y_true\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(      accuracy  precision_macro  recall_macro  f1_macro  balanced_accuracy\n",
       " fold                                                                      \n",
       " 1     0.729050         0.488267      0.540229  0.495812           0.632463\n",
       " 2     0.808530         0.646664      0.607583  0.597418           0.713910\n",
       " 3     0.713554         0.473088      0.561080  0.502891           0.626322,\n",
       "      fold class  precision    recall        f1  support\n",
       " 0       1     0   1.000000  1.000000  1.000000     20.0\n",
       " 1       1     1   0.311828  0.568627  0.402778     51.0\n",
       " 2       1     3   0.552000  1.000000  0.711340     69.0\n",
       " 3       1     4   0.000000  0.000000  0.000000     27.0\n",
       " 4       1     5   0.000000  0.000000  0.000000      0.0\n",
       " ..    ...   ...        ...       ...       ...      ...\n",
       " 138     3    52   1.000000  1.000000  1.000000     84.0\n",
       " 139     3    53   1.000000  1.000000  1.000000     52.0\n",
       " 140     3    56   0.783333  1.000000  0.878505     94.0\n",
       " 141     3    58   1.000000  1.000000  1.000000     46.0\n",
       " 142     3    59   0.000000  0.000000  0.000000     24.0\n",
       " \n",
       " [143 rows x 6 columns])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df = X.copy()\n",
    "evaluate_with_cross_validation(rf_pipeline, x_df, y_species, n_splits=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./bin_3_models_pipelines/3_bin_rf_pipeline.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"bin_3_models_pipelines\"):\n",
    "    os.makedirs(\"bin_3_models_pipelines\")\n",
    "\n",
    "joblib.dump(rf_pipeline, \"./bin_3_models_pipelines/3_bin_rf_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel = 'rbf')\n",
    "svm_pipeline = Pipeline([\n",
    "    ('preproc', preproc),\n",
    "    ('clf', svm_classifier)\n",
    "]\n",
    ")\n",
    "x_df = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_cross_validation(svm_pipeline, x_df, y_species, n_splits=3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA para visualización 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_df = X.copy()\n",
    "# 1) Preprocesado de features usando tu pipeline\n",
    "X_proc = preproc.fit_transform(x_df)\n",
    "\n",
    "# 2) PCA a 3 componentes\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "X_pca = pca.fit_transform(X_proc)\n",
    "\n",
    "# 3) DataFrame para graficar\n",
    "df_vis = pd.DataFrame(X_pca, columns=['PC1','PC2','PC3'])\n",
    "df_vis['genus']   = label_encoder_genus.inverse_transform(y_genus)\n",
    "df_vis['species'] = label_encoder_species.inverse_transform(y_species)\n",
    "\n",
    "# 4) Grafico 3D interactivo – Género\n",
    "fig_genus = px.scatter_3d(\n",
    "    df_vis, x='PC1', y='PC2', z='PC3',\n",
    "    color='genus',\n",
    "    title='PCA 3D interactivo – Género',\n",
    "    labels={'genus':'Género'}\n",
    ")\n",
    "\n",
    "if not os.path.exists(\"bin_3_pca\"):\n",
    "    os.makedirs(\"bin_3_pca\")\n",
    "\n",
    "# 5) O si prefieres guardarlo como HTML y luego incrustarlo:\n",
    "html_path = \"./bin_3_pca/bin_3_pca_genus.html\"\n",
    "\n",
    "display(IFrame(html_path, width=800, height=600))\n",
    "\n",
    "# 6) Mismo para Especie\n",
    "fig_species = px.scatter_3d(\n",
    "    df_vis, x='PC1', y='PC2', z='PC3',\n",
    "    color='species',\n",
    "    title='PCA 3D interactivo – Especie',\n",
    "    labels={'species':'Especie'}\n",
    ")\n",
    "\n",
    "html_path2 = \"./bin_3_pca/bin_3_pca_species.html\"\n",
    "\n",
    "\n",
    "fig_species.write_html(html_path2, include_plotlyjs='cdn')\n",
    "fig_genus.write_html(html_path, include_plotlyjs='cdn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE3 para visualización 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Forzamos renderer interactivo\n",
    "pio.renderers.default = \"iframe_connected\"\n",
    "\n",
    "# 1) Creamos directorio si no existe\n",
    "if not os.path.exists(\"bin_3_tsne3\"):\n",
    "    os.makedirs(\"bin_3_tsne3\")\n",
    "    \n",
    "x_df = X.copy()\n",
    "\n",
    "# 2) Preprocesado de features usando tu pipeline\n",
    "X_proc = preproc.fit_transform(x_df)\n",
    "\n",
    "# 3) t‑SNE a 3 componentes\n",
    "tsne = TSNE(n_components=3, random_state=42, init='pca', learning_rate='auto')\n",
    "X_tsne = tsne.fit_transform(X_proc)\n",
    "\n",
    "# 4) DataFrame para graficar\n",
    "df_vis = pd.DataFrame(X_tsne, columns=['TSNE1','TSNE2','TSNE3'])\n",
    "df_vis['genus']   = label_encoder_genus.inverse_transform(y_genus)\n",
    "df_vis['species'] = label_encoder_species.inverse_transform(y_species)\n",
    "\n",
    "# 5) Gráfico 3D interactivo – Género\n",
    "fig_genus = px.scatter_3d(\n",
    "    df_vis,\n",
    "    x='TSNE1', y='TSNE2', z='TSNE3',\n",
    "    color='genus',\n",
    "    title='t-SNE 3D interactivo – Género',\n",
    "    labels={'genus':'Género'}\n",
    ")\n",
    "html_path = \"./bin_3_tsne3/tsne3_genus.html\"\n",
    "fig_genus.write_html(html_path, include_plotlyjs='cdn')\n",
    "\n",
    "# 6) Gráfico 3D interactivo – Especie\n",
    "fig_species = px.scatter_3d(\n",
    "    df_vis,\n",
    "    x='TSNE1', y='TSNE2', z='TSNE3',\n",
    "    color='species',\n",
    "    title='t-SNE 3D interactivo – Especie',\n",
    "    labels={'species':'Especie'}\n",
    ")\n",
    "html_path2 = \"./bin_3_tsne3/tsne3_species.html\"\n",
    "fig_species.write_html(html_path2, include_plotlyjs='cdn')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
